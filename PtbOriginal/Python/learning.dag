JOB learning_rate-lr_decay0 learning.job DIR . 
JOB learning_rate-lr_decay1 learning.job DIR . 
JOB learning_rate-lr_decay2 learning.job DIR . 
JOB learning_rate-lr_decay3 learning.job DIR . 
JOB learning_rate-lr_decay4 learning.job DIR . 
JOB learning_rate-lr_decay5 learning.job DIR . 
JOB learning_rate-lr_decay6 learning.job DIR . 
JOB learning_rate-lr_decay7 learning.job DIR . 
JOB learning_rate-lr_decay8 learning.job DIR . 

VARS learning_rate-lr_decay0 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="0.2" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="0.1" embedded_size="256" num_run="0" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay1 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="0.2" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="0.5" embedded_size="256" num_run="1" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay2 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="0.2" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="1" embedded_size="256" num_run="2" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay3 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="0.8" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="0.1" embedded_size="256" num_run="3" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay4 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="0.8" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="0.5" embedded_size="256" num_run="4" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay5 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="0.8" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="1" embedded_size="256" num_run="5" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay6 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="1" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="0.1" embedded_size="256" num_run="6" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay7 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="1" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="0.5" embedded_size="256" num_run="7" test_name="learning_rate-lr_decay" 
VARS learning_rate-lr_decay8 vocab_size="10000" optimizer="GradDesc" keep_prob="0.5" max_grad_norm="5" num_layers="2" batch_size="20" init_scale="0.05" max_epoch="6" num_steps="35" max_max_epoch="39" lr_decay="1" loss_function="sequence_loss_by_example" hidden_size="512" learning_rate="1" embedded_size="256" num_run="8" test_name="learning_rate-lr_decay" 
