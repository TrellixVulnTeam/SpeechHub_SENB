03/27/17 17:56:15 ******************************************************
03/27/17 17:56:15 ** condor_scheduniv_exec.417.0 (CONDOR_DAGMAN) STARTING UP
03/27/17 17:56:15 ** /usr/bin/condor_dagman
03/27/17 17:56:15 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
03/27/17 17:56:15 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
03/27/17 17:56:15 ** $CondorVersion: 8.6.1 Mar 01 2017 BuildID: 398585 $
03/27/17 17:56:15 ** $CondorPlatform: x86_64_RedHat7 $
03/27/17 17:56:15 ** PID = 32213
03/27/17 17:56:15 ** Log last touched time unavailable (No such file or directory)
03/27/17 17:56:15 ******************************************************
03/27/17 17:56:15 Using config source: /etc/condor/condor_config
03/27/17 17:56:15 Using local config sources: 
03/27/17 17:56:15    /etc/condor/config.d/00esat.config
03/27/17 17:56:15    /etc/condor/config.d/01java.config
03/27/17 17:56:15    /etc/condor/config.d/80optout_users.config
03/27/17 17:56:15    /etc/condor/condor_config.local
03/27/17 17:56:15 config Macros = 166, Sorted = 166, StringBytes = 6011, TablesBytes = 6048
03/27/17 17:56:15 CLASSAD_CACHING is ENABLED
03/27/17 17:56:15 Daemon Log is logging: D_ALWAYS D_ERROR
03/27/17 17:56:15 DaemonCore: No command port requested.
03/27/17 17:56:15 DAGMAN_USE_STRICT setting: 1
03/27/17 17:56:15 DAGMAN_VERBOSITY setting: 3
03/27/17 17:56:15 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
03/27/17 17:56:15 DAGMAN_DEBUG_CACHE_ENABLE setting: False
03/27/17 17:56:15 DAGMAN_SUBMIT_DELAY setting: 0
03/27/17 17:56:15 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
03/27/17 17:56:15 DAGMAN_STARTUP_CYCLE_DETECT setting: False
03/27/17 17:56:15 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
03/27/17 17:56:15 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
03/27/17 17:56:15 DAGMAN_DEFAULT_PRIORITY setting: 0
03/27/17 17:56:15 DAGMAN_SUPPRESS_NOTIFICATION setting: True
03/27/17 17:56:15 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
03/27/17 17:56:15 DAGMAN_RETRY_SUBMIT_FIRST setting: True
03/27/17 17:56:15 DAGMAN_RETRY_NODE_FIRST setting: False
03/27/17 17:56:15 DAGMAN_MAX_JOBS_IDLE setting: 1000
03/27/17 17:56:15 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
03/27/17 17:56:15 DAGMAN_MAX_PRE_SCRIPTS setting: 20
03/27/17 17:56:15 DAGMAN_MAX_POST_SCRIPTS setting: 20
03/27/17 17:56:15 DAGMAN_MUNGE_NODE_NAMES setting: True
03/27/17 17:56:15 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
03/27/17 17:56:15 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
03/27/17 17:56:15 DAGMAN_ALWAYS_RUN_POST setting: False
03/27/17 17:56:15 DAGMAN_ABORT_DUPLICATES setting: True
03/27/17 17:56:15 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
03/27/17 17:56:15 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
03/27/17 17:56:15 DAGMAN_AUTO_RESCUE setting: True
03/27/17 17:56:15 DAGMAN_MAX_RESCUE_NUM setting: 100
03/27/17 17:56:15 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
03/27/17 17:56:15 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
03/27/17 17:56:15 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
03/27/17 17:56:15 DAGMAN_MAX_JOB_HOLDS setting: 100
03/27/17 17:56:15 DAGMAN_HOLD_CLAIM_TIME setting: 20
03/27/17 17:56:15 ALL_DEBUG setting: 
03/27/17 17:56:15 DAGMAN_DEBUG setting: 
03/27/17 17:56:15 DAGMAN_SUPPRESS_JOB_LOGS setting: False
03/27/17 17:56:15 DAGMAN_REMOVE_NODE_JOBS setting: True
03/27/17 17:56:15 argv[0] == "condor_scheduniv_exec.417.0"
03/27/17 17:56:15 argv[1] == "-Lockfile"
03/27/17 17:56:15 argv[2] == "skipgram.dag.lock"
03/27/17 17:56:15 argv[3] == "-AutoRescue"
03/27/17 17:56:15 argv[4] == "1"
03/27/17 17:56:15 argv[5] == "-DoRescueFrom"
03/27/17 17:56:15 argv[6] == "0"
03/27/17 17:56:15 argv[7] == "-Dag"
03/27/17 17:56:15 argv[8] == "skipgram.dag"
03/27/17 17:56:15 argv[9] == "-Suppress_notification"
03/27/17 17:56:15 argv[10] == "-CsdVersion"
03/27/17 17:56:15 argv[11] == "$CondorVersion: 8.6.1 Mar 01 2017 BuildID: 398585 $"
03/27/17 17:56:15 argv[12] == "-Dagman"
03/27/17 17:56:15 argv[13] == "/usr/bin/condor_dagman"
03/27/17 17:56:15 Workflow batch-name: <skipgram.dag+417>
03/27/17 17:56:15 Workflow accounting_group: <>
03/27/17 17:56:15 Workflow accounting_group_user: <>
03/27/17 17:56:15 Warning: failed to get attribute DAGNodeName
03/27/17 17:56:15 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
03/27/17 17:56:15 Default node log file is: </esat/spchtemp/scratch/wboes/SpeechHub/embedding_experiments/python/./skipgram.dag.nodes.log>
03/27/17 17:56:15 DAG Lockfile will be written to skipgram.dag.lock
03/27/17 17:56:15 DAG Input file is skipgram.dag
03/27/17 17:56:15 Parsing 1 dagfiles
03/27/17 17:56:15 Parsing skipgram.dag ...
03/27/17 17:56:15 Dag contains 1 total jobs
03/27/17 17:56:15 Sleeping for 3 seconds to ensure ProcessId uniqueness
03/27/17 17:56:18 Bootstrapping...
03/27/17 17:56:18 Number of pre-completed nodes: 0
03/27/17 17:56:18 MultiLogFiles: truncating log file /esat/spchtemp/scratch/wboes/SpeechHub/embedding_experiments/python/./skipgram.dag.nodes.log
03/27/17 17:56:18 DAG status: 0 (DAG_STATUS_OK)
03/27/17 17:56:18 Of 1 nodes total:
03/27/17 17:56:18  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/27/17 17:56:18   ===     ===      ===     ===     ===        ===      ===
03/27/17 17:56:18     0       0        0       0       1          0        0
03/27/17 17:56:18 0 job proc(s) currently held
03/27/17 17:56:18 Registering condor_event_timer...
03/27/17 17:56:19 Submitting HTCondor Node skipgram job(s)...
03/27/17 17:56:19 Adding a DAGMan workflow log /esat/spchtemp/scratch/wboes/SpeechHub/embedding_experiments/python/./skipgram.dag.nodes.log
03/27/17 17:56:19 Masking the events recorded in the DAGMAN workflow log
03/27/17 17:56:19 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
03/27/17 17:56:19 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'skipgram -a +DAGManJobId' '=' '417 -a DAGManJobId' '=' '417 -batch-name skipgram.dag+417 -a submit_event_notes' '=' 'DAG' 'Node:' 'skipgram -a dagman_log' '=' '/esat/spchtemp/scratch/wboes/SpeechHub/embedding_experiments/python/./skipgram.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a notification' '=' 'never -a +DAGParentNodeNames' '=' '"" skipgram.job
03/27/17 17:56:19 From submit: Submitting job(s).
03/27/17 17:56:19 From submit: 1 job(s) submitted to cluster 418.
03/27/17 17:56:19 	assigned HTCondor ID (418.0.0)
03/27/17 17:56:19 Just submitted 1 job this cycle...
03/27/17 17:56:19 Currently monitoring 1 HTCondor log file(s)
03/27/17 17:56:19 Reassigning the id of job skipgram from (418.0.0) to (418.0.0)
03/27/17 17:56:19 Event: ULOG_SUBMIT for HTCondor Node skipgram (418.0.0) {03/27/17 17:56:19}
03/27/17 17:56:19 Number of idle job procs: 1
03/27/17 17:56:19 DAG status: 0 (DAG_STATUS_OK)
03/27/17 17:56:19 Of 1 nodes total:
03/27/17 17:56:19  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/27/17 17:56:19   ===     ===      ===     ===     ===        ===      ===
03/27/17 17:56:19     0       0        1       0       0          0        0
03/27/17 17:56:19 0 job proc(s) currently held
03/27/17 17:56:39 Currently monitoring 1 HTCondor log file(s)
03/27/17 17:56:39 Event: ULOG_EXECUTE for HTCondor Node skipgram (418.0.0) {03/27/17 17:56:38}
03/27/17 17:56:39 Number of idle job procs: 0
03/27/17 17:58:05 Currently monitoring 1 HTCondor log file(s)
03/27/17 17:58:05 Event: ULOG_JOB_TERMINATED for HTCondor Node skipgram (418.0.0) {03/27/17 17:58:03}
03/27/17 17:58:05 Number of idle job procs: 0
03/27/17 17:58:05 Node skipgram job proc (418.0.0) failed with status 1.
03/27/17 17:58:05 DAG status: 2 (DAG_STATUS_NODE_FAILED)
03/27/17 17:58:05 Of 1 nodes total:
03/27/17 17:58:05  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/27/17 17:58:05   ===     ===      ===     ===     ===        ===      ===
03/27/17 17:58:05     0       0        0       0       0          0        1
03/27/17 17:58:05 0 job proc(s) currently held
03/27/17 17:58:05 ERROR: the following job(s) failed:
03/27/17 17:58:05 ---------------------- Job ----------------------
03/27/17 17:58:05       Node Name: skipgram
03/27/17 17:58:05            Noop: false
03/27/17 17:58:05          NodeID: 0
03/27/17 17:58:05     Node Status: STATUS_ERROR    
03/27/17 17:58:05 Node return val: 1
03/27/17 17:58:05           Error: Job proc (418.0.0) failed with status 1
03/27/17 17:58:05 Job Submit File: skipgram.job
03/27/17 17:58:05  HTCondor Job ID: (418.0.0)
03/27/17 17:58:05       Q_PARENTS: <END>
03/27/17 17:58:05       Q_WAITING: <END>
03/27/17 17:58:05      Q_CHILDREN: <END>
03/27/17 17:58:05 ---------------------------------------	<END>
03/27/17 17:58:05 Aborting DAG...
03/27/17 17:58:05 Writing Rescue DAG to skipgram.dag.rescue001...
03/27/17 17:58:05 Removing submitted jobs...
03/27/17 17:58:05 Removing any/all submitted HTCondor jobs...
03/27/17 17:58:05 Running: /usr/bin/condor_rm -const DAGManJobId' '=?=' '417
03/27/17 17:58:05 Note: 0 total job deferrals because of -MaxJobs limit (0)
03/27/17 17:58:05 Note: 0 total job deferrals because of -MaxIdle limit (1000)
03/27/17 17:58:05 Note: 0 total job deferrals because of node category throttles
03/27/17 17:58:05 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
03/27/17 17:58:05 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
03/27/17 17:58:05 DAG status: 2 (DAG_STATUS_NODE_FAILED)
03/27/17 17:58:05 Of 1 nodes total:
03/27/17 17:58:05  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
03/27/17 17:58:05   ===     ===      ===     ===     ===        ===      ===
03/27/17 17:58:05     0       0        0       0       0          0        1
03/27/17 17:58:05 0 job proc(s) currently held
03/27/17 17:58:05 Wrote metrics file skipgram.dag.metrics.
03/27/17 17:58:05 Metrics not sent because of PEGASUS_METRICS or CONDOR_DEVELOPERS setting.
03/27/17 17:58:05 **** condor_scheduniv_exec.417.0 (condor_DAGMAN) pid 32213 EXITING WITH STATUS 1
