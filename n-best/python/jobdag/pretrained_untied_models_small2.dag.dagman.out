05/24/17 09:32:25 ******************************************************
05/24/17 09:32:25 ** condor_scheduniv_exec.1443.0 (CONDOR_DAGMAN) STARTING UP
05/24/17 09:32:25 ** /usr/bin/condor_dagman
05/24/17 09:32:25 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
05/24/17 09:32:25 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
05/24/17 09:32:25 ** $CondorVersion: 8.6.2 Apr 23 2017 BuildID: 404257 $
05/24/17 09:32:25 ** $CondorPlatform: x86_64_RedHat7 $
05/24/17 09:32:25 ** PID = 10573
05/24/17 09:32:25 ** Log last touched time unavailable (No such file or directory)
05/24/17 09:32:25 ******************************************************
05/24/17 09:32:25 Using config source: /etc/condor/condor_config
05/24/17 09:32:25 Using local config sources: 
05/24/17 09:32:25    /etc/condor/config.d/00esat.config
05/24/17 09:32:25    /etc/condor/config.d/01java.config
05/24/17 09:32:25    /etc/condor/config.d/80optout_users.config
05/24/17 09:32:25    /etc/condor/condor_config.local
05/24/17 09:32:25 config Macros = 166, Sorted = 166, StringBytes = 6029, TablesBytes = 6048
05/24/17 09:32:25 CLASSAD_CACHING is ENABLED
05/24/17 09:32:25 Daemon Log is logging: D_ALWAYS D_ERROR
05/24/17 09:32:25 DaemonCore: No command port requested.
05/24/17 09:32:25 DAGMAN_USE_STRICT setting: 1
05/24/17 09:32:25 DAGMAN_VERBOSITY setting: 3
05/24/17 09:32:25 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/24/17 09:32:25 DAGMAN_DEBUG_CACHE_ENABLE setting: False
05/24/17 09:32:25 DAGMAN_SUBMIT_DELAY setting: 0
05/24/17 09:32:25 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/24/17 09:32:25 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/24/17 09:32:25 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
05/24/17 09:32:25 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/24/17 09:32:25 DAGMAN_DEFAULT_PRIORITY setting: 0
05/24/17 09:32:25 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/24/17 09:32:25 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/24/17 09:32:25 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/24/17 09:32:25 DAGMAN_RETRY_NODE_FIRST setting: False
05/24/17 09:32:25 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/24/17 09:32:25 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
05/24/17 09:32:25 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/24/17 09:32:25 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/24/17 09:32:25 DAGMAN_MUNGE_NODE_NAMES setting: True
05/24/17 09:32:25 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/24/17 09:32:25 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
05/24/17 09:32:25 DAGMAN_ALWAYS_RUN_POST setting: False
05/24/17 09:32:25 DAGMAN_ABORT_DUPLICATES setting: True
05/24/17 09:32:25 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/24/17 09:32:25 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/24/17 09:32:25 DAGMAN_AUTO_RESCUE setting: True
05/24/17 09:32:25 DAGMAN_MAX_RESCUE_NUM setting: 100
05/24/17 09:32:25 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/24/17 09:32:25 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/24/17 09:32:25 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/24/17 09:32:25 DAGMAN_MAX_JOB_HOLDS setting: 100
05/24/17 09:32:25 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/24/17 09:32:25 ALL_DEBUG setting: 
05/24/17 09:32:25 DAGMAN_DEBUG setting: 
05/24/17 09:32:25 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/24/17 09:32:25 DAGMAN_REMOVE_NODE_JOBS setting: True
05/24/17 09:32:25 argv[0] == "condor_scheduniv_exec.1443.0"
05/24/17 09:32:25 argv[1] == "-Lockfile"
05/24/17 09:32:25 argv[2] == "pretrained_untied_models_small2.dag.lock"
05/24/17 09:32:25 argv[3] == "-AutoRescue"
05/24/17 09:32:25 argv[4] == "1"
05/24/17 09:32:25 argv[5] == "-DoRescueFrom"
05/24/17 09:32:25 argv[6] == "0"
05/24/17 09:32:25 argv[7] == "-Dag"
05/24/17 09:32:25 argv[8] == "pretrained_untied_models_small2.dag"
05/24/17 09:32:25 argv[9] == "-Suppress_notification"
05/24/17 09:32:25 argv[10] == "-CsdVersion"
05/24/17 09:32:25 argv[11] == "$CondorVersion: 8.6.2 Apr 23 2017 BuildID: 404257 $"
05/24/17 09:32:25 argv[12] == "-Dagman"
05/24/17 09:32:25 argv[13] == "/usr/bin/condor_dagman"
05/24/17 09:32:25 Workflow batch-name: <pretrained_untied_models_small2.dag+1443>
05/24/17 09:32:25 Workflow accounting_group: <>
05/24/17 09:32:25 Workflow accounting_group_user: <>
05/24/17 09:32:25 Warning: failed to get attribute DAGNodeName
05/24/17 09:32:25 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/24/17 09:32:25 Default node log file is: </esat/spchtemp/scratch/robbe/SpeechHub/n-best/python/jobdag/./pretrained_untied_models_small2.dag.nodes.log>
05/24/17 09:32:25 DAG Lockfile will be written to pretrained_untied_models_small2.dag.lock
05/24/17 09:32:25 DAG Input file is pretrained_untied_models_small2.dag
05/24/17 09:32:25 Parsing 1 dagfiles
05/24/17 09:32:25 Parsing pretrained_untied_models_small2.dag ...
05/24/17 09:32:25 Dag contains 2 total jobs
05/24/17 09:32:25 Sleeping for 3 seconds to ensure ProcessId uniqueness
05/24/17 09:32:28 Bootstrapping...
05/24/17 09:32:28 Number of pre-completed nodes: 0
05/24/17 09:32:28 MultiLogFiles: truncating log file /esat/spchtemp/scratch/robbe/SpeechHub/n-best/python/jobdag/./pretrained_untied_models_small2.dag.nodes.log
05/24/17 09:32:28 DAG status: 0 (DAG_STATUS_OK)
05/24/17 09:32:28 Of 2 nodes total:
05/24/17 09:32:28  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
05/24/17 09:32:28   ===     ===      ===     ===     ===        ===      ===
05/24/17 09:32:28     0       0        0       0       2          0        0
05/24/17 09:32:28 0 job proc(s) currently held
05/24/17 09:32:28 Registering condor_event_timer...
05/24/17 09:32:29 Submitting HTCondor Node cbow_mean_soft job(s)...
05/24/17 09:32:29 Adding a DAGMan workflow log /esat/spchtemp/scratch/robbe/SpeechHub/n-best/python/jobdag/./pretrained_untied_models_small2.dag.nodes.log
05/24/17 09:32:29 Masking the events recorded in the DAGMAN workflow log
05/24/17 09:32:29 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
05/24/17 09:32:29 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'cbow_mean_soft -a +DAGManJobId' '=' '1443 -a DAGManJobId' '=' '1443 -batch-name pretrained_untied_models_small2.dag+1443 -a submit_event_notes' '=' 'DAG' 'Node:' 'cbow_mean_soft -a dagman_log' '=' '/esat/spchtemp/scratch/robbe/SpeechHub/n-best/python/jobdag/./pretrained_untied_models_small2.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a test_name' '=' 'cbow_mean_soft -a num_run' '=' '0 -a model_name' '=' 'pretrained_untied_models_small -a name' '=' 'pretrained_untied_n_best_cbow_mean_soft_small -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a notification' '=' 'never -a +DAGParentNodeNames' '=' '"" jobdag/cbow_soft.job
05/24/17 09:32:31 From submit: Submitting job(s).
05/24/17 09:32:31 From submit: 1 job(s) submitted to cluster 1444.
05/24/17 09:32:31 	assigned HTCondor ID (1444.0.0)
05/24/17 09:32:31 Submitting HTCondor Node cbow_exp_lstm job(s)...
05/24/17 09:32:31 Adding a DAGMan workflow log /esat/spchtemp/scratch/robbe/SpeechHub/n-best/python/jobdag/./pretrained_untied_models_small2.dag.nodes.log
05/24/17 09:32:31 Masking the events recorded in the DAGMAN workflow log
05/24/17 09:32:31 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
05/24/17 09:32:31 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'cbow_exp_lstm -a +DAGManJobId' '=' '1443 -a DAGManJobId' '=' '1443 -batch-name pretrained_untied_models_small2.dag+1443 -a submit_event_notes' '=' 'DAG' 'Node:' 'cbow_exp_lstm -a dagman_log' '=' '/esat/spchtemp/scratch/robbe/SpeechHub/n-best/python/jobdag/./pretrained_untied_models_small2.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a test_name' '=' 'cbow_exp_lstm -a num_run' '=' '0 -a model_name' '=' 'pretrained_untied_models_small -a name' '=' 'pretrained_untied_n_best_cbow_exp_lstm_small -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a notification' '=' 'never -a +DAGParentNodeNames' '=' '"" jobdag/cbow_lstm.job
05/24/17 09:32:31 From submit: Submitting job(s).
05/24/17 09:32:31 From submit: 1 job(s) submitted to cluster 1445.
05/24/17 09:32:31 	assigned HTCondor ID (1445.0.0)
05/24/17 09:32:31 Just submitted 2 jobs this cycle...
05/24/17 09:32:31 Currently monitoring 1 HTCondor log file(s)
05/24/17 09:32:31 Reassigning the id of job cbow_mean_soft from (1444.0.0) to (1444.0.0)
05/24/17 09:32:31 Event: ULOG_SUBMIT for HTCondor Node cbow_mean_soft (1444.0.0) {05/24/17 09:32:31}
05/24/17 09:32:31 Number of idle job procs: 1
05/24/17 09:32:31 Reassigning the id of job cbow_exp_lstm from (1445.0.0) to (1445.0.0)
05/24/17 09:32:31 Event: ULOG_SUBMIT for HTCondor Node cbow_exp_lstm (1445.0.0) {05/24/17 09:32:31}
05/24/17 09:32:31 Number of idle job procs: 2
05/24/17 09:32:31 DAG status: 0 (DAG_STATUS_OK)
05/24/17 09:32:31 Of 2 nodes total:
05/24/17 09:32:31  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
05/24/17 09:32:31   ===     ===      ===     ===     ===        ===      ===
05/24/17 09:32:31     0       0        2       0       0          0        0
05/24/17 09:32:31 0 job proc(s) currently held
05/24/17 09:42:34 603 seconds since last log event
05/24/17 09:42:34 Pending DAG nodes:
05/24/17 09:42:34   Node cbow_mean_soft, HTCondor ID 1444, status STATUS_SUBMITTED
05/24/17 09:42:34   Node cbow_exp_lstm, HTCondor ID 1445, status STATUS_SUBMITTED
05/24/17 09:52:34 1203 seconds since last log event
05/24/17 09:52:34 Pending DAG nodes:
05/24/17 09:52:34   Node cbow_mean_soft, HTCondor ID 1444, status STATUS_SUBMITTED
05/24/17 09:52:34   Node cbow_exp_lstm, HTCondor ID 1445, status STATUS_SUBMITTED
05/24/17 10:02:36 1805 seconds since last log event
05/24/17 10:02:36 Pending DAG nodes:
05/24/17 10:02:36   Node cbow_mean_soft, HTCondor ID 1444, status STATUS_SUBMITTED
05/24/17 10:02:36   Node cbow_exp_lstm, HTCondor ID 1445, status STATUS_SUBMITTED
05/24/17 10:06:02 ******************************************************
05/24/17 10:06:02 ** condor_scheduniv_exec.1443.0 (CONDOR_DAGMAN) STARTING UP
05/24/17 10:06:02 ** /usr/bin/condor_dagman
05/24/17 10:06:02 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
05/24/17 10:06:02 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
05/24/17 10:06:02 ** $CondorVersion: 8.6.2 Apr 23 2017 BuildID: 404257 $
05/24/17 10:06:02 ** $CondorPlatform: x86_64_RedHat7 $
05/24/17 10:06:02 ** PID = 16202
05/24/17 10:06:02 ** Log last touched 5/24 10:05:29
05/24/17 10:06:02 ******************************************************
05/24/17 10:06:02 Using config source: /etc/condor/condor_config
05/24/17 10:06:02 Using local config sources: 
05/24/17 10:06:02    /etc/condor/config.d/00esat.config
05/24/17 10:06:02    /etc/condor/config.d/01java.config
05/24/17 10:06:02    /etc/condor/config.d/80optout_users.config
05/24/17 10:06:02    /etc/condor/condor_config.local
05/24/17 10:06:02 config Macros = 170, Sorted = 170, StringBytes = 6175, TablesBytes = 6192
05/24/17 10:06:02 CLASSAD_CACHING is ENABLED
05/24/17 10:06:02 Daemon Log is logging: D_ALWAYS D_ERROR
05/24/17 10:06:02 DaemonCore: No command port requested.
05/24/17 10:06:02 DAGMAN_USE_STRICT setting: 1
05/24/17 10:06:02 DAGMAN_VERBOSITY setting: 3
05/24/17 10:06:02 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
05/24/17 10:06:02 DAGMAN_DEBUG_CACHE_ENABLE setting: False
05/24/17 10:06:03 DAGMAN_SUBMIT_DELAY setting: 0
05/24/17 10:06:03 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
05/24/17 10:06:03 DAGMAN_STARTUP_CYCLE_DETECT setting: False
05/24/17 10:06:03 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
05/24/17 10:06:03 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
05/24/17 10:06:03 DAGMAN_DEFAULT_PRIORITY setting: 0
05/24/17 10:06:03 DAGMAN_SUPPRESS_NOTIFICATION setting: True
05/24/17 10:06:03 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
05/24/17 10:06:03 DAGMAN_RETRY_SUBMIT_FIRST setting: True
05/24/17 10:06:03 DAGMAN_RETRY_NODE_FIRST setting: False
05/24/17 10:06:03 DAGMAN_MAX_JOBS_IDLE setting: 1000
05/24/17 10:06:03 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
05/24/17 10:06:03 DAGMAN_MAX_PRE_SCRIPTS setting: 20
05/24/17 10:06:03 DAGMAN_MAX_POST_SCRIPTS setting: 20
05/24/17 10:06:03 DAGMAN_MUNGE_NODE_NAMES setting: True
05/24/17 10:06:03 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
05/24/17 10:06:03 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
05/24/17 10:06:03 DAGMAN_ALWAYS_RUN_POST setting: False
05/24/17 10:06:03 DAGMAN_ABORT_DUPLICATES setting: True
05/24/17 10:06:03 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
05/24/17 10:06:03 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
05/24/17 10:06:03 DAGMAN_AUTO_RESCUE setting: True
05/24/17 10:06:03 DAGMAN_MAX_RESCUE_NUM setting: 100
05/24/17 10:06:03 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
05/24/17 10:06:03 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
05/24/17 10:06:03 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
05/24/17 10:06:03 DAGMAN_MAX_JOB_HOLDS setting: 100
05/24/17 10:06:03 DAGMAN_HOLD_CLAIM_TIME setting: 20
05/24/17 10:06:03 ALL_DEBUG setting: 
05/24/17 10:06:03 DAGMAN_DEBUG setting: 
05/24/17 10:06:03 DAGMAN_SUPPRESS_JOB_LOGS setting: False
05/24/17 10:06:03 DAGMAN_REMOVE_NODE_JOBS setting: True
05/24/17 10:06:03 argv[0] == "condor_scheduniv_exec.1443.0"
05/24/17 10:06:03 argv[1] == "-Lockfile"
05/24/17 10:06:03 argv[2] == "pretrained_untied_models_small2.dag.lock"
05/24/17 10:06:03 argv[3] == "-AutoRescue"
05/24/17 10:06:03 argv[4] == "1"
05/24/17 10:06:03 argv[5] == "-DoRescueFrom"
05/24/17 10:06:03 argv[6] == "0"
05/24/17 10:06:03 argv[7] == "-Dag"
05/24/17 10:06:03 argv[8] == "pretrained_untied_models_small2.dag"
05/24/17 10:06:03 argv[9] == "-Suppress_notification"
05/24/17 10:06:03 argv[10] == "-CsdVersion"
05/24/17 10:06:03 argv[11] == "$CondorVersion: 8.6.2 Apr 23 2017 BuildID: 404257 $"
05/24/17 10:06:03 argv[12] == "-Dagman"
05/24/17 10:06:03 argv[13] == "/usr/bin/condor_dagman"
05/24/17 10:06:03 Workflow batch-name: <pretrained_untied_models_small2.dag+1443>
05/24/17 10:06:03 Workflow accounting_group: <>
05/24/17 10:06:03 Workflow accounting_group_user: <>
05/24/17 10:06:03 Warning: failed to get attribute DAGNodeName
05/24/17 10:06:03 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
05/24/17 10:06:03 Default node log file is: </esat/spchtemp/scratch/robbe/SpeechHub/n-best/python/jobdag/./pretrained_untied_models_small2.dag.nodes.log>
05/24/17 10:06:03 DAG Lockfile will be written to pretrained_untied_models_small2.dag.lock
05/24/17 10:06:03 DAG Input file is pretrained_untied_models_small2.dag
05/24/17 10:06:03 Parsing 1 dagfiles
05/24/17 10:06:03 Parsing pretrained_untied_models_small2.dag ...
05/24/17 10:06:03 Dag contains 2 total jobs
05/24/17 10:06:03 Lock file pretrained_untied_models_small2.dag.lock detected, 
05/24/17 10:06:03 Duplicate DAGMan PID 10573 is no longer alive; this DAGMan should continue.
05/24/17 10:06:03 Using default node job log file
05/24/17 10:06:03 Sleeping for 3 seconds to ensure ProcessId uniqueness
05/24/17 10:06:06 Bootstrapping...
05/24/17 10:06:06 Number of pre-completed nodes: 0
05/24/17 10:06:06 Running in RECOVERY mode... >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
05/24/17 10:06:06 Currently monitoring 1 HTCondor log file(s)
05/24/17 10:06:06 Event: ULOG_SUBMIT for HTCondor Node cbow_mean_soft (1444.0.0) {05/24/17 09:32:31} [recovery mode]
05/24/17 10:06:06 Number of idle job procs: 1
05/24/17 10:06:06 Event: ULOG_SUBMIT for HTCondor Node cbow_exp_lstm (1445.0.0) {05/24/17 09:32:31} [recovery mode]
05/24/17 10:06:06 Number of idle job procs: 2
05/24/17 10:06:06     ------------------------------
05/24/17 10:06:06        HTCondor Recovery Complete
05/24/17 10:06:06     ------------------------------
05/24/17 10:06:06 ...done with RECOVERY mode <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
05/24/17 10:06:06 DAG status: 0 (DAG_STATUS_OK)
05/24/17 10:06:06 Of 2 nodes total:
05/24/17 10:06:06  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
05/24/17 10:06:06   ===     ===      ===     ===     ===        ===      ===
05/24/17 10:06:06     0       0        2       0       0          0        0
05/24/17 10:06:06 0 job proc(s) currently held
05/24/17 10:06:06 DAG status: 0 (DAG_STATUS_OK)
05/24/17 10:06:06 Of 2 nodes total:
05/24/17 10:06:06  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
05/24/17 10:06:06   ===     ===      ===     ===     ===        ===      ===
05/24/17 10:06:06     0       0        2       0       0          0        0
05/24/17 10:06:06 0 job proc(s) currently held
05/24/17 10:06:06 Registering condor_event_timer...
05/24/17 10:06:07 Currently monitoring 1 HTCondor log file(s)
05/24/17 10:06:07 DAG status: 0 (DAG_STATUS_OK)
05/24/17 10:06:07 Of 2 nodes total:
05/24/17 10:06:07  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
05/24/17 10:06:07   ===     ===      ===     ===     ===        ===      ===
05/24/17 10:06:07     0       0        2       0       0          0        0
05/24/17 10:06:07 0 job proc(s) currently held
05/24/17 10:16:09 602 seconds since last log event
05/24/17 10:16:09 Pending DAG nodes:
05/24/17 10:16:09   Node cbow_mean_soft, HTCondor ID 1444, status STATUS_SUBMITTED
05/24/17 10:16:09   Node cbow_exp_lstm, HTCondor ID 1445, status STATUS_SUBMITTED
05/24/17 10:20:03 Received SIGUSR1
05/24/17 10:20:03 Aborting DAG...
05/24/17 10:20:03 Writing Rescue DAG to pretrained_untied_models_small2.dag.rescue001...
05/24/17 10:20:03 Removing submitted jobs...
05/24/17 10:20:03 Removing any/all submitted HTCondor jobs...
05/24/17 10:20:03 Running: /usr/bin/condor_rm -const DAGManJobId' '=?=' '1443
05/24/17 10:20:03 Note: 0 total job deferrals because of -MaxJobs limit (0)
05/24/17 10:20:03 Note: 0 total job deferrals because of -MaxIdle limit (1000)
05/24/17 10:20:03 Note: 0 total job deferrals because of node category throttles
05/24/17 10:20:03 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
05/24/17 10:20:03 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
05/24/17 10:20:03 DAG status: 4 (DAG_STATUS_RM)
05/24/17 10:20:03 Of 2 nodes total:
05/24/17 10:20:03  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
05/24/17 10:20:03   ===     ===      ===     ===     ===        ===      ===
05/24/17 10:20:03     0       0        2       0       0          0        0
05/24/17 10:20:03 0 job proc(s) currently held
05/24/17 10:20:03 Wrote metrics file pretrained_untied_models_small2.dag.metrics.
05/24/17 10:20:03 Metrics not sent because of PEGASUS_METRICS or CONDOR_DEVELOPERS setting.
05/24/17 10:20:03 **** condor_scheduniv_exec.1443.0 (condor_DAGMAN) pid 16202 EXITING WITH STATUS 2
