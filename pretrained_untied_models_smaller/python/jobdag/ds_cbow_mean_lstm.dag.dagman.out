04/12/17 14:43:28 ******************************************************
04/12/17 14:43:28 ** condor_scheduniv_exec.16.0 (CONDOR_DAGMAN) STARTING UP
04/12/17 14:43:28 ** /usr/bin/condor_dagman
04/12/17 14:43:28 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
04/12/17 14:43:28 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
04/12/17 14:43:28 ** $CondorVersion: 8.6.1 Mar 01 2017 BuildID: 398585 $
04/12/17 14:43:28 ** $CondorPlatform: x86_64_RedHat7 $
04/12/17 14:43:28 ** PID = 10642
04/12/17 14:43:28 ** Log last touched time unavailable (No such file or directory)
04/12/17 14:43:28 ******************************************************
04/12/17 14:43:28 Using config source: /etc/condor/condor_config
04/12/17 14:43:28 Using local config sources: 
04/12/17 14:43:28    /etc/condor/config.d/00esat.config
04/12/17 14:43:28    /etc/condor/config.d/01java.config
04/12/17 14:43:28    /etc/condor/config.d/80optout_users.config
04/12/17 14:43:28    /etc/condor/condor_config.local
04/12/17 14:43:28 config Macros = 174, Sorted = 174, StringBytes = 6660, TablesBytes = 6336
04/12/17 14:43:28 CLASSAD_CACHING is ENABLED
04/12/17 14:43:28 Daemon Log is logging: D_ALWAYS D_ERROR
04/12/17 14:43:28 DaemonCore: No command port requested.
04/12/17 14:43:28 DAGMAN_USE_STRICT setting: 1
04/12/17 14:43:28 DAGMAN_VERBOSITY setting: 3
04/12/17 14:43:28 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/12/17 14:43:28 DAGMAN_DEBUG_CACHE_ENABLE setting: False
04/12/17 14:43:28 DAGMAN_SUBMIT_DELAY setting: 0
04/12/17 14:43:28 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/12/17 14:43:28 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/12/17 14:43:28 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
04/12/17 14:43:28 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/12/17 14:43:28 DAGMAN_DEFAULT_PRIORITY setting: 0
04/12/17 14:43:28 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/12/17 14:43:28 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/12/17 14:43:28 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/12/17 14:43:28 DAGMAN_RETRY_NODE_FIRST setting: False
04/12/17 14:43:28 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/12/17 14:43:28 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
04/12/17 14:43:28 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/12/17 14:43:28 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/12/17 14:43:28 DAGMAN_MUNGE_NODE_NAMES setting: True
04/12/17 14:43:28 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/12/17 14:43:28 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
04/12/17 14:43:28 DAGMAN_ALWAYS_RUN_POST setting: False
04/12/17 14:43:28 DAGMAN_ABORT_DUPLICATES setting: True
04/12/17 14:43:28 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/12/17 14:43:28 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/12/17 14:43:28 DAGMAN_AUTO_RESCUE setting: True
04/12/17 14:43:28 DAGMAN_MAX_RESCUE_NUM setting: 100
04/12/17 14:43:28 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/12/17 14:43:28 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/12/17 14:43:28 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/12/17 14:43:28 DAGMAN_MAX_JOB_HOLDS setting: 100
04/12/17 14:43:28 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/12/17 14:43:28 ALL_DEBUG setting: 
04/12/17 14:43:28 DAGMAN_DEBUG setting: 
04/12/17 14:43:28 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/12/17 14:43:28 DAGMAN_REMOVE_NODE_JOBS setting: True
04/12/17 14:43:28 argv[0] == "condor_scheduniv_exec.16.0"
04/12/17 14:43:28 argv[1] == "-Lockfile"
04/12/17 14:43:28 argv[2] == "ds_cbow_mean_lstm.dag.lock"
04/12/17 14:43:28 argv[3] == "-AutoRescue"
04/12/17 14:43:28 argv[4] == "1"
04/12/17 14:43:28 argv[5] == "-DoRescueFrom"
04/12/17 14:43:28 argv[6] == "0"
04/12/17 14:43:28 argv[7] == "-Dag"
04/12/17 14:43:28 argv[8] == "ds_cbow_mean_lstm.dag"
04/12/17 14:43:28 argv[9] == "-Suppress_notification"
04/12/17 14:43:28 argv[10] == "-CsdVersion"
04/12/17 14:43:28 argv[11] == "$CondorVersion: 8.6.1 Mar 01 2017 BuildID: 398585 $"
04/12/17 14:43:28 argv[12] == "-Dagman"
04/12/17 14:43:28 argv[13] == "/usr/bin/condor_dagman"
04/12/17 14:43:28 Workflow batch-name: <ds_cbow_mean_lstm.dag+16>
04/12/17 14:43:28 Workflow accounting_group: <>
04/12/17 14:43:28 Workflow accounting_group_user: <>
04/12/17 14:43:28 Warning: failed to get attribute DAGNodeName
04/12/17 14:43:28 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/12/17 14:43:28 Default node log file is: </esat/spchtemp/scratch/wboes/SpeechHub/pretrained_untied_models_smaller/python/jobdag/./ds_cbow_mean_lstm.dag.nodes.log>
04/12/17 14:43:28 DAG Lockfile will be written to ds_cbow_mean_lstm.dag.lock
04/12/17 14:43:28 DAG Input file is ds_cbow_mean_lstm.dag
04/12/17 14:43:28 Parsing 1 dagfiles
04/12/17 14:43:28 Parsing ds_cbow_mean_lstm.dag ...
04/12/17 14:43:28 Dag contains 2 total jobs
04/12/17 14:43:28 Sleeping for 3 seconds to ensure ProcessId uniqueness
04/12/17 14:43:31 Bootstrapping...
04/12/17 14:43:31 Number of pre-completed nodes: 0
04/12/17 14:43:31 MultiLogFiles: truncating log file /esat/spchtemp/scratch/wboes/SpeechHub/pretrained_untied_models_smaller/python/jobdag/./ds_cbow_mean_lstm.dag.nodes.log
04/12/17 14:43:31 DAG status: 0 (DAG_STATUS_OK)
04/12/17 14:43:31 Of 2 nodes total:
04/12/17 14:43:31  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
04/12/17 14:43:31   ===     ===      ===     ===     ===        ===      ===
04/12/17 14:43:31     0       0        0       0       1          1        0
04/12/17 14:43:31 0 job proc(s) currently held
04/12/17 14:43:31 Registering condor_event_timer...
04/12/17 14:43:32 Submitting HTCondor Node cbow_mean_lstm job(s)...
04/12/17 14:43:32 Adding a DAGMan workflow log /esat/spchtemp/scratch/wboes/SpeechHub/pretrained_untied_models_smaller/python/jobdag/./ds_cbow_mean_lstm.dag.nodes.log
04/12/17 14:43:32 Masking the events recorded in the DAGMAN workflow log
04/12/17 14:43:32 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
04/12/17 14:43:32 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'cbow_mean_lstm -a +DAGManJobId' '=' '16 -a DAGManJobId' '=' '16 -batch-name ds_cbow_mean_lstm.dag+16 -a submit_event_notes' '=' 'DAG' 'Node:' 'cbow_mean_lstm -a dagman_log' '=' '/esat/spchtemp/scratch/wboes/SpeechHub/pretrained_untied_models_smaller/python/jobdag/./ds_cbow_mean_lstm.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a data_set' '=' 'ds -a test_name' '=' 'cbow_mean_lstm -a num_run' '=' '0 -a combination' '=' 'mean -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a +KeepClaimIdle' '=' '20 -a notification' '=' 'never -a +DAGParentNodeNames' '=' '"" jobdag/cbow_lstm.job
04/12/17 14:43:32 From submit: Submitting job(s).
04/12/17 14:43:32 From submit: 1 job(s) submitted to cluster 18.
04/12/17 14:43:32 	assigned HTCondor ID (18.0.0)
04/12/17 14:43:32 Just submitted 1 job this cycle...
04/12/17 14:43:32 Currently monitoring 1 HTCondor log file(s)
04/12/17 14:43:32 Reassigning the id of job cbow_mean_lstm from (18.0.0) to (18.0.0)
04/12/17 14:43:32 Event: ULOG_SUBMIT for HTCondor Node cbow_mean_lstm (18.0.0) {04/12/17 14:43:32}
04/12/17 14:43:32 Number of idle job procs: 1
04/12/17 14:43:32 DAG status: 0 (DAG_STATUS_OK)
04/12/17 14:43:32 Of 2 nodes total:
04/12/17 14:43:32  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
04/12/17 14:43:32   ===     ===      ===     ===     ===        ===      ===
04/12/17 14:43:32     0       0        1       0       0          1        0
04/12/17 14:43:32 0 job proc(s) currently held
04/12/17 14:53:34 602 seconds since last log event
04/12/17 14:53:34 Pending DAG nodes:
04/12/17 14:53:34   Node cbow_mean_lstm, HTCondor ID 18, status STATUS_SUBMITTED
