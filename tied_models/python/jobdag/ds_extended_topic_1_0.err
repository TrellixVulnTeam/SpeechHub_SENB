I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
/users/start2014/r0364650/.local/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.
  warnings.warn("Pattern library is not installed, lemmatization won't be available.")
/users/start2014/r0364650/.local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  "Converting sparse IndexedSlices to a dense Tensor of unknown shape. "
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 980 Ti
major: 5 minor: 2 memoryClockRate (GHz) 1.19
pciBusID 0000:01:00.0
Total memory: 5.93GiB
Free memory: 5.84GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980 Ti, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 7533 get requests, put_count=7467 evicted_count=1000 eviction_rate=0.133923 and unsatisfied allocation rate=0.154786
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 11151 get requests, put_count=11040 evicted_count=1000 eviction_rate=0.0905797 and unsatisfied allocation rate=0.101695
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 256 to 281
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2023406 get requests, put_count=2023435 evicted_count=1000 eviction_rate=0.000494209 and unsatisfied allocation rate=0.000509043
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 21938376 get requests, put_count=21938405 evicted_count=11000 eviction_rate=0.000501404 and unsatisfied allocation rate=0.000502772
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 41691924 get requests, put_count=41691953 evicted_count=21000 eviction_rate=0.000503694 and unsatisfied allocation rate=0.000504414
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 61569354 get requests, put_count=61569383 evicted_count=31000 eviction_rate=0.000503497 and unsatisfied allocation rate=0.000503984
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 81416752 get requests, put_count=81416781 evicted_count=41000 eviction_rate=0.000503582 and unsatisfied allocation rate=0.00050395
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 101290428 get requests, put_count=101290457 evicted_count=51000 eviction_rate=0.000503503 and unsatisfied allocation rate=0.000503799
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 121265462 get requests, put_count=121265491 evicted_count=61000 eviction_rate=0.000503029 and unsatisfied allocation rate=0.000503276
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 141187940 get requests, put_count=141187969 evicted_count=71000 eviction_rate=0.000502876 and unsatisfied allocation rate=0.000503088
