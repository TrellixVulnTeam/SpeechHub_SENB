04/07/17 11:29:58 ******************************************************
04/07/17 11:29:58 ** condor_scheduniv_exec.677.0 (CONDOR_DAGMAN) STARTING UP
04/07/17 11:29:58 ** /usr/bin/condor_dagman
04/07/17 11:29:58 ** SubsystemInfo: name=DAGMAN type=DAGMAN(10) class=DAEMON(1)
04/07/17 11:29:58 ** Configuration: subsystem:DAGMAN local:<NONE> class:DAEMON
04/07/17 11:29:58 ** $CondorVersion: 8.6.1 Mar 01 2017 BuildID: 398585 $
04/07/17 11:29:58 ** $CondorPlatform: x86_64_RedHat7 $
04/07/17 11:29:58 ** PID = 22646
04/07/17 11:29:58 ** Log last touched time unavailable (No such file or directory)
04/07/17 11:29:58 ******************************************************
04/07/17 11:29:58 Using config source: /etc/condor/condor_config
04/07/17 11:29:58 Using local config sources: 
04/07/17 11:29:58    /etc/condor/config.d/00esat.config
04/07/17 11:29:58    /etc/condor/config.d/01java.config
04/07/17 11:29:58    /etc/condor/config.d/80optout_users.config
04/07/17 11:29:58    /etc/condor/condor_config.local
04/07/17 11:29:58 config Macros = 166, Sorted = 166, StringBytes = 6021, TablesBytes = 6048
04/07/17 11:29:58 CLASSAD_CACHING is ENABLED
04/07/17 11:29:58 Daemon Log is logging: D_ALWAYS D_ERROR
04/07/17 11:29:58 DaemonCore: No command port requested.
04/07/17 11:29:58 DAGMAN_USE_STRICT setting: 1
04/07/17 11:29:58 DAGMAN_VERBOSITY setting: 3
04/07/17 11:29:58 DAGMAN_DEBUG_CACHE_SIZE setting: 5242880
04/07/17 11:29:58 DAGMAN_DEBUG_CACHE_ENABLE setting: False
04/07/17 11:29:58 DAGMAN_SUBMIT_DELAY setting: 0
04/07/17 11:29:58 DAGMAN_MAX_SUBMIT_ATTEMPTS setting: 6
04/07/17 11:29:58 DAGMAN_STARTUP_CYCLE_DETECT setting: False
04/07/17 11:29:58 DAGMAN_MAX_SUBMITS_PER_INTERVAL setting: 5
04/07/17 11:29:58 DAGMAN_USER_LOG_SCAN_INTERVAL setting: 5
04/07/17 11:29:58 DAGMAN_DEFAULT_PRIORITY setting: 0
04/07/17 11:29:58 DAGMAN_SUPPRESS_NOTIFICATION setting: True
04/07/17 11:29:58 allow_events (DAGMAN_ALLOW_EVENTS) setting: 114
04/07/17 11:29:58 DAGMAN_RETRY_SUBMIT_FIRST setting: True
04/07/17 11:29:58 DAGMAN_RETRY_NODE_FIRST setting: False
04/07/17 11:29:58 DAGMAN_MAX_JOBS_IDLE setting: 1000
04/07/17 11:29:58 DAGMAN_MAX_JOBS_SUBMITTED setting: 0
04/07/17 11:29:58 DAGMAN_MAX_PRE_SCRIPTS setting: 20
04/07/17 11:29:58 DAGMAN_MAX_POST_SCRIPTS setting: 20
04/07/17 11:29:58 DAGMAN_MUNGE_NODE_NAMES setting: True
04/07/17 11:29:58 DAGMAN_PROHIBIT_MULTI_JOBS setting: False
04/07/17 11:29:58 DAGMAN_SUBMIT_DEPTH_FIRST setting: False
04/07/17 11:29:58 DAGMAN_ALWAYS_RUN_POST setting: False
04/07/17 11:29:58 DAGMAN_ABORT_DUPLICATES setting: True
04/07/17 11:29:58 DAGMAN_ABORT_ON_SCARY_SUBMIT setting: True
04/07/17 11:29:58 DAGMAN_PENDING_REPORT_INTERVAL setting: 600
04/07/17 11:29:58 DAGMAN_AUTO_RESCUE setting: True
04/07/17 11:29:58 DAGMAN_MAX_RESCUE_NUM setting: 100
04/07/17 11:29:58 DAGMAN_WRITE_PARTIAL_RESCUE setting: True
04/07/17 11:29:58 DAGMAN_DEFAULT_NODE_LOG setting: @(DAG_DIR)/@(DAG_FILE).nodes.log
04/07/17 11:29:58 DAGMAN_GENERATE_SUBDAG_SUBMITS setting: True
04/07/17 11:29:58 DAGMAN_MAX_JOB_HOLDS setting: 100
04/07/17 11:29:58 DAGMAN_HOLD_CLAIM_TIME setting: 20
04/07/17 11:29:58 ALL_DEBUG setting: 
04/07/17 11:29:58 DAGMAN_DEBUG setting: 
04/07/17 11:29:58 DAGMAN_SUPPRESS_JOB_LOGS setting: False
04/07/17 11:29:58 DAGMAN_REMOVE_NODE_JOBS setting: True
04/07/17 11:29:58 argv[0] == "condor_scheduniv_exec.677.0"
04/07/17 11:29:58 argv[1] == "-Lockfile"
04/07/17 11:29:58 argv[2] == "topic_gen_512_5.dag.lock"
04/07/17 11:29:58 argv[3] == "-AutoRescue"
04/07/17 11:29:58 argv[4] == "1"
04/07/17 11:29:58 argv[5] == "-DoRescueFrom"
04/07/17 11:29:58 argv[6] == "0"
04/07/17 11:29:58 argv[7] == "-Dag"
04/07/17 11:29:58 argv[8] == "topic_gen_512_5.dag"
04/07/17 11:29:58 argv[9] == "-Suppress_notification"
04/07/17 11:29:58 argv[10] == "-CsdVersion"
04/07/17 11:29:58 argv[11] == "$CondorVersion: 8.6.1 Mar 01 2017 BuildID: 398585 $"
04/07/17 11:29:58 argv[12] == "-Dagman"
04/07/17 11:29:58 argv[13] == "/usr/bin/condor_dagman"
04/07/17 11:29:58 Workflow batch-name: <topic_gen_512_5.dag+677>
04/07/17 11:29:58 Workflow accounting_group: <>
04/07/17 11:29:58 Workflow accounting_group_user: <>
04/07/17 11:29:58 Warning: failed to get attribute DAGNodeName
04/07/17 11:29:58 DAGMAN_LOG_ON_NFS_IS_ERROR setting: False
04/07/17 11:29:58 Default node log file is: </esat/spchtemp/scratch/robbe/SpeechHub/topic_experiments/python/jobdag/./topic_gen_512_5.dag.nodes.log>
04/07/17 11:29:58 DAG Lockfile will be written to topic_gen_512_5.dag.lock
04/07/17 11:29:58 DAG Input file is topic_gen_512_5.dag
04/07/17 11:29:58 Parsing 1 dagfiles
04/07/17 11:29:58 Parsing topic_gen_512_5.dag ...
04/07/17 11:29:58 Dag contains 1 total jobs
04/07/17 11:29:58 Sleeping for 3 seconds to ensure ProcessId uniqueness
04/07/17 11:30:01 Bootstrapping...
04/07/17 11:30:01 Number of pre-completed nodes: 0
04/07/17 11:30:01 MultiLogFiles: truncating log file /esat/spchtemp/scratch/robbe/SpeechHub/topic_experiments/python/jobdag/./topic_gen_512_5.dag.nodes.log
04/07/17 11:30:01 DAG status: 0 (DAG_STATUS_OK)
04/07/17 11:30:01 Of 1 nodes total:
04/07/17 11:30:01  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
04/07/17 11:30:01   ===     ===      ===     ===     ===        ===      ===
04/07/17 11:30:01     0       0        0       0       1          0        0
04/07/17 11:30:01 0 job proc(s) currently held
04/07/17 11:30:01 Registering condor_event_timer...
04/07/17 11:30:02 Submitting HTCondor Node topic_generation0a job(s)...
04/07/17 11:30:02 Adding a DAGMan workflow log /esat/spchtemp/scratch/robbe/SpeechHub/topic_experiments/python/jobdag/./topic_gen_512_5.dag.nodes.log
04/07/17 11:30:02 Masking the events recorded in the DAGMAN workflow log
04/07/17 11:30:02 Mask for workflow log is 0,1,2,4,5,7,9,10,11,12,13,16,17,24,27
04/07/17 11:30:02 submitting: /usr/bin/condor_submit -a dag_node_name' '=' 'topic_generation0a -a +DAGManJobId' '=' '677 -a DAGManJobId' '=' '677 -batch-name topic_gen_512_5.dag+677 -a submit_event_notes' '=' 'DAG' 'Node:' 'topic_generation0a -a dagman_log' '=' '/esat/spchtemp/scratch/robbe/SpeechHub/topic_experiments/python/jobdag/./topic_gen_512_5.dag.nodes.log -a +DAGManNodesMask' '=' '"0,1,2,4,5,7,9,10,11,12,13,16,17,24,27" -a data_set' '=' 'ds -a nb_topics' '=' '512 -a sentences_per_document' '=' '5 -a DAG_STATUS' '=' '0 -a FAILED_COUNT' '=' '0 -a notification' '=' 'never -a +DAGParentNodeNames' '=' '"" jobdag/topic_test_a.job
04/07/17 11:30:02 From submit: Submitting job(s).
04/07/17 11:30:02 From submit: 1 job(s) submitted to cluster 679.
04/07/17 11:30:02 From submit: WARNING: the line 'CLAIM_WORKLIFE = 1200 * 3' was unused by condor_submit. Is it a typo?
04/07/17 11:30:02 From submit: WARNING: the line 'NEGOTIATOR_CONSIDER_PREEMPTION = False' was unused by condor_submit. Is it a typo?
04/07/17 11:30:02 From submit: WARNING: the line 'PREEMPT = False' was unused by condor_submit. Is it a typo?
04/07/17 11:30:02 From submit: WARNING: the line 'PREEMPTION_REQUIREMENTS = False' was unused by condor_submit. Is it a typo?
04/07/17 11:30:02 	assigned HTCondor ID (679.0.0)
04/07/17 11:30:02 Just submitted 1 job this cycle...
04/07/17 11:30:02 Currently monitoring 1 HTCondor log file(s)
04/07/17 11:30:02 Reassigning the id of job topic_generation0a from (679.0.0) to (679.0.0)
04/07/17 11:30:02 Event: ULOG_SUBMIT for HTCondor Node topic_generation0a (679.0.0) {04/07/17 11:30:02}
04/07/17 11:30:02 Number of idle job procs: 1
04/07/17 11:30:02 DAG status: 0 (DAG_STATUS_OK)
04/07/17 11:30:02 Of 1 nodes total:
04/07/17 11:30:02  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
04/07/17 11:30:02   ===     ===      ===     ===     ===        ===      ===
04/07/17 11:30:02     0       0        1       0       0          0        0
04/07/17 11:30:02 0 job proc(s) currently held
04/07/17 11:30:07 Currently monitoring 1 HTCondor log file(s)
04/07/17 11:30:07 Event: ULOG_EXECUTE for HTCondor Node topic_generation0a (679.0.0) {04/07/17 11:30:07}
04/07/17 11:30:07 Number of idle job procs: 0
04/07/17 11:40:09 602 seconds since last log event
04/07/17 11:40:09 Pending DAG nodes:
04/07/17 11:40:09   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 11:50:11 1204 seconds since last log event
04/07/17 11:50:11 Pending DAG nodes:
04/07/17 11:50:11   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 12:00:14 1807 seconds since last log event
04/07/17 12:00:14 Pending DAG nodes:
04/07/17 12:00:14   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 12:10:17 2410 seconds since last log event
04/07/17 12:10:17 Pending DAG nodes:
04/07/17 12:10:17   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 12:20:20 3013 seconds since last log event
04/07/17 12:20:20 Pending DAG nodes:
04/07/17 12:20:20   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 12:30:22 3615 seconds since last log event
04/07/17 12:30:22 Pending DAG nodes:
04/07/17 12:30:22   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 12:40:25 4218 seconds since last log event
04/07/17 12:40:25 Pending DAG nodes:
04/07/17 12:40:25   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 12:50:29 4822 seconds since last log event
04/07/17 12:50:29 Pending DAG nodes:
04/07/17 12:50:29   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 13:00:30 5423 seconds since last log event
04/07/17 13:00:30 Pending DAG nodes:
04/07/17 13:00:30   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 13:10:32 6025 seconds since last log event
04/07/17 13:10:32 Pending DAG nodes:
04/07/17 13:10:32   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 13:20:36 6629 seconds since last log event
04/07/17 13:20:36 Pending DAG nodes:
04/07/17 13:20:36   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 13:30:39 7232 seconds since last log event
04/07/17 13:30:39 Pending DAG nodes:
04/07/17 13:30:39   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 13:40:42 7835 seconds since last log event
04/07/17 13:40:42 Pending DAG nodes:
04/07/17 13:40:42   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 13:50:45 8438 seconds since last log event
04/07/17 13:50:45 Pending DAG nodes:
04/07/17 13:50:45   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 13:56:02 Currently monitoring 1 HTCondor log file(s)
04/07/17 13:56:02 Event: ULOG_JOB_EVICTED for HTCondor Node topic_generation0a (679.0.0) {04/07/17 13:56:02}
04/07/17 13:56:02 Number of idle job procs: 1
04/07/17 13:57:07 Currently monitoring 1 HTCondor log file(s)
04/07/17 13:57:07 Event: ULOG_EXECUTE for HTCondor Node topic_generation0a (679.0.0) {04/07/17 13:57:05}
04/07/17 13:57:07 Number of idle job procs: 0
04/07/17 14:07:10 603 seconds since last log event
04/07/17 14:07:10 Pending DAG nodes:
04/07/17 14:07:10   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 14:17:13 1206 seconds since last log event
04/07/17 14:17:13 Pending DAG nodes:
04/07/17 14:17:13   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 14:18:24 Currently monitoring 1 HTCondor log file(s)
04/07/17 14:18:24 Event: ULOG_JOB_EVICTED for HTCondor Node topic_generation0a (679.0.0) {04/07/17 14:18:21}
04/07/17 14:18:24 Number of idle job procs: 1
04/07/17 14:20:24 Currently monitoring 1 HTCondor log file(s)
04/07/17 14:20:24 Event: ULOG_EXECUTE for HTCondor Node topic_generation0a (679.0.0) {04/07/17 14:20:22}
04/07/17 14:20:24 Number of idle job procs: 0
04/07/17 14:28:22 Currently monitoring 1 HTCondor log file(s)
04/07/17 14:28:22 Event: ULOG_JOB_EVICTED for HTCondor Node topic_generation0a (679.0.0) {04/07/17 14:28:18}
04/07/17 14:28:22 Number of idle job procs: 1
04/07/17 14:30:27 Currently monitoring 1 HTCondor log file(s)
04/07/17 14:30:27 Event: ULOG_EXECUTE for HTCondor Node topic_generation0a (679.0.0) {04/07/17 14:30:23}
04/07/17 14:30:27 Number of idle job procs: 0
04/07/17 14:40:29 602 seconds since last log event
04/07/17 14:40:29 Pending DAG nodes:
04/07/17 14:40:29   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 14:50:32 1205 seconds since last log event
04/07/17 14:50:32 Pending DAG nodes:
04/07/17 14:50:32   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 15:00:35 1808 seconds since last log event
04/07/17 15:00:35 Pending DAG nodes:
04/07/17 15:00:35   Node topic_generation0a, HTCondor ID 679, status STATUS_SUBMITTED
04/07/17 15:01:02 Received SIGUSR1
04/07/17 15:01:02 Aborting DAG...
04/07/17 15:01:02 Writing Rescue DAG to topic_gen_512_5.dag.rescue001...
04/07/17 15:01:02 Removing submitted jobs...
04/07/17 15:01:02 Removing any/all submitted HTCondor jobs...
04/07/17 15:01:02 Running: /usr/bin/condor_rm -const DAGManJobId' '=?=' '677
04/07/17 15:01:02 Note: 0 total job deferrals because of -MaxJobs limit (0)
04/07/17 15:01:02 Note: 0 total job deferrals because of -MaxIdle limit (1000)
04/07/17 15:01:02 Note: 0 total job deferrals because of node category throttles
04/07/17 15:01:02 Note: 0 total PRE script deferrals because of -MaxPre limit (20) or DEFER
04/07/17 15:01:02 Note: 0 total POST script deferrals because of -MaxPost limit (20) or DEFER
04/07/17 15:01:02 DAG status: 4 (DAG_STATUS_RM)
04/07/17 15:01:02 Of 1 nodes total:
04/07/17 15:01:02  Done     Pre   Queued    Post   Ready   Un-Ready   Failed
04/07/17 15:01:02   ===     ===      ===     ===     ===        ===      ===
04/07/17 15:01:02     0       0        1       0       0          0        0
04/07/17 15:01:02 0 job proc(s) currently held
04/07/17 15:01:02 Wrote metrics file topic_gen_512_5.dag.metrics.
04/07/17 15:01:02 Metrics not sent because of PEGASUS_METRICS or CONDOR_DEVELOPERS setting.
04/07/17 15:01:02 **** condor_scheduniv_exec.677.0 (condor_DAGMAN) pid 22646 EXITING WITH STATUS 2
